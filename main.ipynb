{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using a simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a neural network for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNc(nn.Module):\n",
    "    def __init__(self, emb_size=64, **kwargs):\n",
    "        \"\"\"CNN  based analogy classifier model.\n",
    "\n",
    "                It generates a value between 0 and 1 (0 for invalid, 1 for valid) based on four input\n",
    "        vectors.\n",
    "                1st layer (convolutional): 128 filters (= kernels) of size h × w = 1 × 2 with strides (1, 2)\n",
    "        and relu activation.\n",
    "                2nd layer (convolutional): 64 filters of size (2, 2) with strides (2, 2) and relu activation.\n",
    "                3rd layer (dense, equivalent to linear for PyTorch): one output and sigmoid activation.\n",
    "\n",
    "                Argument:\n",
    "                emb_size -- the size of the input vectors\"\"\"\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.conv1 = nn.Conv2d(1, 128, (1, 2), stride=(1, 2))\n",
    "        self.conv2 = nn.Conv2d(128, 64, (2, 2), stride=(2, 2))\n",
    "        self.linear = nn.Linear(64 * (emb_size // 2), 1)\n",
    "\n",
    "    def flatten(self, t):\n",
    "        \"\"\"Flattens  the input tensor.\"\"\"\n",
    "        t = t.reshape(t.size()[0], -1)\n",
    "        return t\n",
    "\n",
    "    def forward(self, a, b, c, d, p=0):\n",
    "        \"\"\"\n",
    "\n",
    "        Expected  input shape:\n",
    "        - a, b, c, d: [batch_size, emb_size]\n",
    "        \"\"\"\n",
    "        image = torch.stack([a, b, c, d], dim=2)\n",
    "\n",
    "        # apply dropout\n",
    "        if p > 0:\n",
    "            image = F.dropout(image, p)\n",
    "\n",
    "        x = self.conv1(image.unsqueeze(-3))\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        output = torch.sigmoid(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity1</th>\n",
       "      <th>Entity2</th>\n",
       "      <th>Entity3</th>\n",
       "      <th>Entity4</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pat_Roberts</td>\n",
       "      <td>Politician</td>\n",
       "      <td>Yuliya_Menshova</td>\n",
       "      <td>News_presenter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>catatonic_schizophrenia_Q1432717</td>\n",
       "      <td>catatonic_excitement_Q57769952</td>\n",
       "      <td>Naantali</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>François_Hollande</td>\n",
       "      <td>French-American_Foundation</td>\n",
       "      <td>Brazil_national_football_team</td>\n",
       "      <td>CONMEBOL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Glee_(season_2)</td>\n",
       "      <td>British_Isles</td>\n",
       "      <td>Wyk_auf_Föhr</td>\n",
       "      <td>Iburi_Subprefecture</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anagrelide</td>\n",
       "      <td>Amiodarone</td>\n",
       "      <td>Maria_Pogonowska</td>\n",
       "      <td>Faculty_of_Physics_of_University_of_Warsaw_Q93...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_Q4109978</td>\n",
       "      <td>Hebrew_language</td>\n",
       "      <td>Men_Without_Women_Q12039063</td>\n",
       "      <td>Theologian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The_Vampire_Diaries_(season_4)</td>\n",
       "      <td>After_School_Special_(The_Vampire_Diaries)</td>\n",
       "      <td>San_Sebastián</td>\n",
       "      <td>Basque_Country_(autonomous_community)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Georg_Mancelius</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Heroes_(season_2)</td>\n",
       "      <td>Kindred_(Heroes)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_Q30926938</td>\n",
       "      <td>Psychiatrist</td>\n",
       "      <td>Nadarajan_Periasamy</td>\n",
       "      <td>motorcycle_racer_Q3014296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jean-Marc_Vacheron</td>\n",
       "      <td>Princess_of_Asturias_Award_for_Communications_...</td>\n",
       "      <td>Marilyn_Monroe</td>\n",
       "      <td>Dave_McKean</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jerzy_Kluger</td>\n",
       "      <td>Kraków</td>\n",
       "      <td>Christine_Norden</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>_Q12881518</td>\n",
       "      <td>Television_presenter</td>\n",
       "      <td>Óscar_Urralburu</td>\n",
       "      <td>trade_unionist_Q15627169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Andorra–Catalonia_border_Q56400610</td>\n",
       "      <td>Catalan_Pyrénées_Q11941708</td>\n",
       "      <td>United_States_Military_Academy</td>\n",
       "      <td>West_Point,_New_York</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vincent_Price</td>\n",
       "      <td>Victoria_Price</td>\n",
       "      <td>The_Tsarevich_(1929_film)</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Champagne_Jam</td>\n",
       "      <td>Aubrey_Beauclerk,_5th_Duke_of_St_Albans</td>\n",
       "      <td>Ebonshire_-_Volume_3</td>\n",
       "      <td>San_Fernando,_Chile</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pencho_Slaveykov</td>\n",
       "      <td>Translator</td>\n",
       "      <td>Guillaume_Henri_Dufour</td>\n",
       "      <td>Politician</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Infanta_Maria_Anna_of_Portugal_(1843–1884)</td>\n",
       "      <td>Film_producer</td>\n",
       "      <td>False_Dmitry_I</td>\n",
       "      <td>Marina_Mniszech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Andy_Roddick</td>\n",
       "      <td>tennis_player_Q10833314</td>\n",
       "      <td>Dougray_Scott</td>\n",
       "      <td>Actor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>_Q17227895</td>\n",
       "      <td>Magazine_House_Q11339926</td>\n",
       "      <td>_Q20596865</td>\n",
       "      <td>Gwasg_Carreg_Gwalch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>José_Pont_y_Gol_Q684950</td>\n",
       "      <td>Tarragona</td>\n",
       "      <td>Luca_Maria_Capponi_Q16657876</td>\n",
       "      <td>Triora</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Entity1  \\\n",
       "0                                  Pat_Roberts   \n",
       "1             catatonic_schizophrenia_Q1432717   \n",
       "2                            François_Hollande   \n",
       "3                              Glee_(season_2)   \n",
       "4                                   Anagrelide   \n",
       "5                                    _Q4109978   \n",
       "6               The_Vampire_Diaries_(season_4)   \n",
       "7                              Georg_Mancelius   \n",
       "8                                   _Q30926938   \n",
       "9                           Jean-Marc_Vacheron   \n",
       "10                                Jerzy_Kluger   \n",
       "11                                  _Q12881518   \n",
       "12          Andorra–Catalonia_border_Q56400610   \n",
       "13                               Vincent_Price   \n",
       "14                               Champagne_Jam   \n",
       "15                            Pencho_Slaveykov   \n",
       "16  Infanta_Maria_Anna_of_Portugal_(1843–1884)   \n",
       "17                                Andy_Roddick   \n",
       "18                                  _Q17227895   \n",
       "19                     José_Pont_y_Gol_Q684950   \n",
       "\n",
       "                                              Entity2  \\\n",
       "0                                          Politician   \n",
       "1                      catatonic_excitement_Q57769952   \n",
       "2                          French-American_Foundation   \n",
       "3                                       British_Isles   \n",
       "4                                          Amiodarone   \n",
       "5                                     Hebrew_language   \n",
       "6          After_School_Special_(The_Vampire_Diaries)   \n",
       "7                                           Indonesia   \n",
       "8                                        Psychiatrist   \n",
       "9   Princess_of_Asturias_Award_for_Communications_...   \n",
       "10                                             Kraków   \n",
       "11                               Television_presenter   \n",
       "12                         Catalan_Pyrénées_Q11941708   \n",
       "13                                     Victoria_Price   \n",
       "14            Aubrey_Beauclerk,_5th_Duke_of_St_Albans   \n",
       "15                                         Translator   \n",
       "16                                      Film_producer   \n",
       "17                            tennis_player_Q10833314   \n",
       "18                           Magazine_House_Q11339926   \n",
       "19                                          Tarragona   \n",
       "\n",
       "                           Entity3  \\\n",
       "0                  Yuliya_Menshova   \n",
       "1                         Naantali   \n",
       "2    Brazil_national_football_team   \n",
       "3                     Wyk_auf_Föhr   \n",
       "4                 Maria_Pogonowska   \n",
       "5      Men_Without_Women_Q12039063   \n",
       "6                    San_Sebastián   \n",
       "7                Heroes_(season_2)   \n",
       "8              Nadarajan_Periasamy   \n",
       "9                   Marilyn_Monroe   \n",
       "10                Christine_Norden   \n",
       "11                 Óscar_Urralburu   \n",
       "12  United_States_Military_Academy   \n",
       "13       The_Tsarevich_(1929_film)   \n",
       "14            Ebonshire_-_Volume_3   \n",
       "15          Guillaume_Henri_Dufour   \n",
       "16                  False_Dmitry_I   \n",
       "17                   Dougray_Scott   \n",
       "18                      _Q20596865   \n",
       "19    Luca_Maria_Capponi_Q16657876   \n",
       "\n",
       "                                              Entity4  Label  \n",
       "0                                      News_presenter      1  \n",
       "1                                           Sheffield      0  \n",
       "2                                            CONMEBOL      1  \n",
       "3                                 Iburi_Subprefecture      0  \n",
       "4   Faculty_of_Physics_of_University_of_Warsaw_Q93...      0  \n",
       "5                                          Theologian      0  \n",
       "6               Basque_Country_(autonomous_community)      0  \n",
       "7                                    Kindred_(Heroes)      0  \n",
       "8                           motorcycle_racer_Q3014296      1  \n",
       "9                                         Dave_McKean      0  \n",
       "10                                         Sunderland      1  \n",
       "11                           trade_unionist_Q15627169      1  \n",
       "12                               West_Point,_New_York      1  \n",
       "13                                         Sunderland      0  \n",
       "14                                San_Fernando,_Chile      0  \n",
       "15                                         Politician      1  \n",
       "16                                    Marina_Mniszech      0  \n",
       "17                                              Actor      1  \n",
       "18                                Gwasg_Carreg_Gwalch      1  \n",
       "19                                             Triora      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./shuffled_combined_dataset.csv')\n",
    "\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity1</th>\n",
       "      <th>Entity2</th>\n",
       "      <th>Entity3</th>\n",
       "      <th>Entity4</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pat roberts</td>\n",
       "      <td>politician</td>\n",
       "      <td>yuliya menshova</td>\n",
       "      <td>news presenter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>catatonic schizophrenia q1432717</td>\n",
       "      <td>catatonic excitement q57769952</td>\n",
       "      <td>naantali</td>\n",
       "      <td>sheffield</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>françois hollande</td>\n",
       "      <td>french-american foundation</td>\n",
       "      <td>brazil national football team</td>\n",
       "      <td>conmebol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glee season 2</td>\n",
       "      <td>british isles</td>\n",
       "      <td>wyk auf föhr</td>\n",
       "      <td>iburi subprefecture</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anagrelide</td>\n",
       "      <td>amiodarone</td>\n",
       "      <td>maria pogonowska</td>\n",
       "      <td>faculty of physics of university of warsaw q93...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Entity1                         Entity2  \\\n",
       "0                       pat roberts                      politician   \n",
       "1  catatonic schizophrenia q1432717  catatonic excitement q57769952   \n",
       "2                 françois hollande      french-american foundation   \n",
       "3                     glee season 2                   british isles   \n",
       "4                        anagrelide                      amiodarone   \n",
       "\n",
       "                         Entity3  \\\n",
       "0                yuliya menshova   \n",
       "1                       naantali   \n",
       "2  brazil national football team   \n",
       "3                   wyk auf föhr   \n",
       "4               maria pogonowska   \n",
       "\n",
       "                                             Entity4  Label  \n",
       "0                                     news presenter      1  \n",
       "1                                          sheffield      0  \n",
       "2                                           conmebol      1  \n",
       "3                                iburi subprefecture      0  \n",
       "4  faculty of physics of university of warsaw q93...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up dataset by replacing _ with space, and make it lower case\n",
    "for col in ['Entity1', 'Entity2', 'Entity3', 'Entity4']:\n",
    "    data[col] = data[col].str.replace('_', ' ').str.lower().replace(r'[()]', '', regex=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity1</th>\n",
       "      <th>Entity2</th>\n",
       "      <th>Entity3</th>\n",
       "      <th>Entity4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>adriano celentano</td>\n",
       "      <td>film score composer q1415090</td>\n",
       "      <td>shibusawa eiichi</td>\n",
       "      <td>economist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>stan laurel</td>\n",
       "      <td>film actor q10800557</td>\n",
       "      <td>shulamit katznelson</td>\n",
       "      <td>activist q15253558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>afdera franchetti</td>\n",
       "      <td>italy</td>\n",
       "      <td>yen ching-ling q10924380</td>\n",
       "      <td>republic of china 1912–1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>itsuki akata q11373859</td>\n",
       "      <td>japan</td>\n",
       "      <td>josé ribamar de faria machado q29107255</td>\n",
       "      <td>brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>q15953145</td>\n",
       "      <td>fondremand</td>\n",
       "      <td>rivière-héva</td>\n",
       "      <td>la vallée-de-l'or regional county municipality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Entity1                       Entity2  \\\n",
       "999995       adriano celentano  film score composer q1415090   \n",
       "999996             stan laurel          film actor q10800557   \n",
       "999997       afdera franchetti                         italy   \n",
       "999998  itsuki akata q11373859                         japan   \n",
       "999999               q15953145                    fondremand   \n",
       "\n",
       "                                        Entity3  \\\n",
       "999995                         shibusawa eiichi   \n",
       "999996                      shulamit katznelson   \n",
       "999997                 yen ching-ling q10924380   \n",
       "999998  josé ribamar de faria machado q29107255   \n",
       "999999                             rivière-héva   \n",
       "\n",
       "                                               Entity4  \n",
       "999995                                       economist  \n",
       "999996                              activist q15253558  \n",
       "999997                     republic of china 1912–1949  \n",
       "999998                                          brazil  \n",
       "999999  la vallée-de-l'or regional county municipality  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split X, and Y\n",
    "X = data[['Entity1', 'Entity2', 'Entity3', 'Entity4']]\n",
    "y = data['Label']\n",
    "\n",
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Embedding Size\n",
    "emb_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert sentence to word vector using Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all sentences into a single list\n",
    "all_sentences = [sentence.split() for sublist in X.values for sentence in sublist]\n",
    "\n",
    "all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=all_sentences, vector_size=emb_size, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# Save the model\n",
    "word2vec_model.save('word2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word2vec_model.wv[\"pat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec_model = Word2Vec.load(\"word2vec_model\")\n",
    "\n",
    "# Define sentence_to_vector Function\n",
    "def sentence_to_vector(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence and returns the average of all word vectors in the sentence.\n",
    "    \"\"\"\n",
    "    words = filter(lambda x: x in word2vec_model.wv, sentence.split())\n",
    "    word_vectors = np.array([word2vec_model.wv[w] for w in words])\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    \n",
    "    return np.mean(word_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb = X.copy()\n",
    "\n",
    "# Convert sentences to vectors\n",
    "for column in X.columns:\n",
    "    X_emb[column] = X_emb[column].apply(sentence_to_vector)\n",
    "\n",
    "y_emb = y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Method of Converting Sentence to Word Vector using Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained spaCy model (English)\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Define process_sentence Function which converts a sentence to a word vector\n",
    "def process_sentence(sentence):\n",
    "    \"\"\"\n",
    "    This function takes a sentence and returns a tensor of word embeddings.\n",
    "    \"\"\"\n",
    "    with nlp.disable_pipes():\n",
    "        doc = nlp(sentence)\n",
    "        word_vectors = [word.vector for word in doc]\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "\n",
    "X_emb = X.copy().map(process_sentence)\n",
    "y_emb = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity1</th>\n",
       "      <th>Entity2</th>\n",
       "      <th>Entity3</th>\n",
       "      <th>Entity4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-3.6452, -1.5158, 0.45935, -2.026125, 0.61745...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-1.0559, -0.9508, 0.80744, 0.2634, -0.55012, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>[0.18266, -1.18043, -0.15500003, 2.93255, 3.80...</td>\n",
       "      <td>[-2.8140333, -0.064466655, -1.7309667, -4.413,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-1.4905, 0.9294, -1.2411, 0.094085, 1.96755, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-3.9826, 1.1531, 1.7868, 3.7107, 7.1926, 1.02...</td>\n",
       "      <td>[-2.19712, 1.1288999, -3.39506, 2.48582, 1.946...</td>\n",
       "      <td>[-4.98295, -4.0700502, -0.61006504, 1.76276, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-1.4837, -4.541, -3.2058, 2.3037, 4.7184, -2....</td>\n",
       "      <td>[1.2412833, -3.1828334, 0.12455667, 2.0108333,...</td>\n",
       "      <td>[-1.5349, -2.0664, -2.2445, 3.077, 5.2252, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-3.3196335, 0.2565, 0.6242, 3.62443, 4.8059, ...</td>\n",
       "      <td>[-1.7039224, -2.6593997, -1.1798732, 4.1722155...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Entity1  \\\n",
       "999995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "999996  [0.18266, -1.18043, -0.15500003, 2.93255, 3.80...   \n",
       "999997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "999998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "999999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                  Entity2  \\\n",
       "999995  [-3.6452, -1.5158, 0.45935, -2.026125, 0.61745...   \n",
       "999996  [-2.8140333, -0.064466655, -1.7309667, -4.413,...   \n",
       "999997  [-3.9826, 1.1531, 1.7868, 3.7107, 7.1926, 1.02...   \n",
       "999998  [-1.4837, -4.541, -3.2058, 2.3037, 4.7184, -2....   \n",
       "999999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                  Entity3  \\\n",
       "999995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "999996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "999997  [-2.19712, 1.1288999, -3.39506, 2.48582, 1.946...   \n",
       "999998  [1.2412833, -3.1828334, 0.12455667, 2.0108333,...   \n",
       "999999  [-3.3196335, 0.2565, 0.6242, 3.62443, 4.8059, ...   \n",
       "\n",
       "                                                  Entity4  \n",
       "999995  [-1.0559, -0.9508, 0.80744, 0.2634, -0.55012, ...  \n",
       "999996  [-1.4905, 0.9294, -1.2411, 0.094085, 1.96755, ...  \n",
       "999997  [-4.98295, -4.0700502, -0.61006504, 1.76276, 1...  \n",
       "999998  [-1.5349, -2.0664, -2.2445, 3.077, 5.2252, -1....  \n",
       "999999  [-1.7039224, -2.6593997, -1.1798732, 4.1722155...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train vs Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_emb, y_emb, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert DataFrame to PyTorch Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Temp\\ipykernel_11672\\3173343474.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  X_train_tensors = [torch.tensor(X_train[col].tolist(), dtype=torch.float32).to(device) for col in X_train.columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert numpy objects to torch tensors\n",
    "X_train_tensors = [torch.tensor(X_train[col].tolist(), dtype=torch.float32).to(device) for col in X_train.columns]\n",
    "X_test_tensors = [torch.tensor(X_test[col].tolist(), dtype=torch.float32).to(device) for col in X_test.columns]\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.tolist(), dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.tolist(), dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 10 800\n",
      "[1,   200] loss: 0.612\n",
      "[1,   400] loss: 0.556\n",
      "[1,   600] loss: 0.533\n",
      "[1,   800] loss: 0.517\n",
      "[2,   200] loss: 0.511\n",
      "[2,   400] loss: 0.507\n",
      "[2,   600] loss: 0.502\n",
      "[2,   800] loss: 0.500\n",
      "[3,   200] loss: 0.499\n",
      "[3,   400] loss: 0.497\n",
      "[3,   600] loss: 0.492\n",
      "[3,   800] loss: 0.489\n",
      "[4,   200] loss: 0.490\n",
      "[4,   400] loss: 0.489\n",
      "[4,   600] loss: 0.485\n",
      "[4,   800] loss: 0.482\n",
      "[5,   200] loss: 0.483\n",
      "[5,   400] loss: 0.481\n",
      "[5,   600] loss: 0.478\n",
      "[5,   800] loss: 0.476\n",
      "[6,   200] loss: 0.477\n",
      "[6,   400] loss: 0.475\n",
      "[6,   600] loss: 0.472\n",
      "[6,   800] loss: 0.470\n",
      "[7,   200] loss: 0.471\n",
      "[7,   400] loss: 0.471\n",
      "[7,   600] loss: 0.469\n",
      "[7,   800] loss: 0.467\n",
      "[8,   200] loss: 0.468\n",
      "[8,   400] loss: 0.469\n",
      "[8,   600] loss: 0.467\n",
      "[8,   800] loss: 0.465\n",
      "[9,   200] loss: 0.466\n",
      "[9,   400] loss: 0.467\n",
      "[9,   600] loss: 0.466\n",
      "[9,   800] loss: 0.464\n",
      "[10,   200] loss: 0.464\n",
      "[10,   400] loss: 0.465\n",
      "[10,   600] loss: 0.464\n",
      "[10,   800] loss: 0.462\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = ANNc(emb_size=emb_size).to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the number of epochs\n",
    "n_epochs = 10\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 1000\n",
    "\n",
    "# Define the number of batches\n",
    "n_batches = len(X_train) // batch_size\n",
    "\n",
    "print(batch_size, n_epochs, n_batches)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        # Get the inputs and labels\n",
    "        inputs = [X_train_tensors[j][start:end] for j in range(4)]\n",
    "        labels = y_train_tensor[start:end]\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(*inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test data: 75 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test)):\n",
    "        inputs = [X_test_tensors[j][i:i+1] for j in range(4)]\n",
    "        labels = y_test_tensor[i]\n",
    "\n",
    "        outputs = model(*inputs)\n",
    "        predicted = torch.round(outputs)\n",
    "\n",
    "        total += 1\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test data: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78    100373\n",
      "           1       0.83      0.65      0.73     99627\n",
      "\n",
      "    accuracy                           0.76    200000\n",
      "   macro avg       0.77      0.76      0.76    200000\n",
      "weighted avg       0.77      0.76      0.76    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe the model accuracy\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test)):\n",
    "        inputs = [X_test_tensors[j][i:i+1] for j in range(4)]\n",
    "        labels = y_test_tensor[i]\n",
    "\n",
    "        outputs = model(*inputs)\n",
    "        predicted = torch.round(outputs)\n",
    "        y_pred.append(predicted.item())\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
